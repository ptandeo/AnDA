{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "pylab.rcParams['figure.figsize'] = (16, 9)\n",
    "\n",
    "# analog data assimilation\n",
    "import sys\n",
    "sys.path.insert(0, '/AnDA_CME')\n",
    "from AnDA_codes.AnDA_generate_data import AnDA_generate_data\n",
    "from AnDA_codes.AnDA_analog_forecasting import AnDA_analog_forecasting\n",
    "from AnDA_codes.AnDA_model_forecasting import AnDA_model_forecasting\n",
    "from AnDA_codes.AnDA_data_assimilation import AnDA_data_assimilation\n",
    "from AnDA_codes.AnDA_stat_functions import AnDA_RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to compute model evidence ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mooving_average(x, N):\n",
    "    out = np.zeros_like(x, dtype=np.float64)\n",
    "    dim_len = x.shape[0]\n",
    "    for i in range(dim_len):\n",
    "        if N%2 == 0:\n",
    "            a, b = i - (N-1)//2, i + (N-1)//2 + 2\n",
    "        else:\n",
    "            a, b = i - (N-1)//2, i + (N-1)//2 + 1\n",
    "\n",
    "        #cap indices to min and max indices\n",
    "        a = max(0, a)\n",
    "        b = min(dim_len, b)\n",
    "        out[i] = np.mean(x[a:b])\n",
    "    return out\n",
    "\n",
    "def model_evidence(ll_good, ll_bad, K, yo):\n",
    "    out = np.sum((mooving_average(ll_good-ll_bad,K)>0)/len(yo.time)*100)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|█▌                                    | 398/10000 [00:13<05:21, 29.87it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-e46489cc3602>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mAnDA_analog_forecasting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;31m# run the analog data assimilation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mx_hat_analog_good\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnDA_data_assimilation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;31m# loop on F values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AnDA_CME\\AnDA_codes\\AnDA_data_assimilation.py\u001b[0m in \u001b[0;36mAnDA_data_assimilation\u001b[1;34m(yo, DA)\u001b[0m\n\u001b[0;32m     48\u001b[0m                 \u001b[0mxf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[0mxf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm_xa_part_tmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpart\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m                 \u001b[0mm_xa_part\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mm_xa_part_tmp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[0mxf_part\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-e46489cc3602>\u001b[0m in \u001b[0;36mm\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mAnDA_analog_forecasting\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mAF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m \u001b[1;31m# run the analog data assimilation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[0mx_hat_analog_good\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnDA_data_assimilation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Dropbox\\AnDA_CME\\AnDA_codes\\AnDA_analog_forecasting.py\u001b[0m in \u001b[0;36mAnDA_analog_forecasting\u001b[1;34m(x, AF)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;31m# find the indices and distances of the k-nearest neighbors (knn)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mkdt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKDTree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatalog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0manalogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_var_neighboor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleaf_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0mdist_knn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_knn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi_var_neighboor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;31m# parameter of normalization for the kernels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K = 1000 # maximum size of the evidence window\n",
    "\n",
    "# parameters\n",
    "class GD:\n",
    "    model = 'Lorenz_96'\n",
    "    class parameters:\n",
    "        F = 8\n",
    "        J = 40\n",
    "    dt_integration = 0.05 # integration time\n",
    "    dt_states = 1 # number of integration times between consecutive states (for xt and catalog)\n",
    "    dt_obs = 1 # number of integration times between consecutive observations (for yo)\n",
    "    var_obs = [17,18,19,20,21] # indices of the observed variables\n",
    "    nb_loop_train = 1000 # size of the catalog\n",
    "    nb_loop_test = 500 # size of the true state and noisy observations\n",
    "    sigma2_catalog = 0.001 # variance of the model error to generate the catalog   \n",
    "    sigma2_obs = 1 # variance of the observation error to generate observations    \n",
    "# run the data generation\n",
    "catalog_good, xt, yo = AnDA_generate_data(GD)\n",
    "\n",
    "# keep only a subset of variables\n",
    "catalog_good.analogs = catalog_good.analogs[:,17:22]\n",
    "catalog_good.successors = catalog_good.successors[:,17:22]\n",
    "yo.values = yo.values[:,17:22]\n",
    "n = catalog_good.analogs.shape[1]\n",
    "global_analog_matrix=np.ones([n,n])\n",
    "\n",
    "# parameters of the analog forecasting method\n",
    "class AF:\n",
    "    k = 50 # number of analogs\n",
    "    neighborhood = global_analog_matrix\n",
    "    catalog = catalog_good # catalog with analogs and successors\n",
    "    regression = 'local_linear' # chosen regression ('locally_constant', 'increment', 'local_linear')\n",
    "    sampling = 'gaussian' # chosen sampler ('gaussian', 'multinomial')\n",
    "# parameters of the filtering method\n",
    "class DA:\n",
    "    method = 'AnEnKF' # chosen method ('AnEnKF', 'AnEnKS', 'AnPF')\n",
    "    N = 100 # number of members (AnEnKF/AnEnKS) or particles (AnPF)\n",
    "    xb = xt.values[0,17:22]; B = 0.1*np.eye(n)\n",
    "    H = np.eye(n)\n",
    "    R = GD.sigma2_obs*np.eye(n)\n",
    "    @staticmethod\n",
    "    def m(x):\n",
    "        return AnDA_analog_forecasting(x,AF)\n",
    "# run the analog data assimilation\n",
    "x_hat_analog_good = AnDA_data_assimilation(yo, DA)\n",
    "\n",
    "# loop on F values\n",
    "F_values = array([6,7,9,10])\n",
    "N_iter = 1\n",
    "tab_ME_AnDA = zeros([N_iter,len(F_values),K])\n",
    "for i_iter in range(N_iter):\n",
    "    print(i_iter)\n",
    "    for i_F in range(len(F_values)):\n",
    "        print(F_values[i_F])\n",
    "        # parameters\n",
    "        class GD:\n",
    "            model = 'Lorenz_96'\n",
    "            class parameters:\n",
    "                F = F_values[i_F]\n",
    "                J = 40\n",
    "            dt_integration = 0.05 # integration time\n",
    "            dt_states = 1 # number of integration times between consecutive states (for xt and catalog)\n",
    "            dt_obs = 1 # number of integration times between consecutive observations (for yo)\n",
    "            var_obs = [17,18,19,20,21] # indices of the observed variables\n",
    "            nb_loop_train = 1000 # size of the catalog\n",
    "            nb_loop_test = 500 # size of the true state and noisy observations\n",
    "            sigma2_catalog = 0.001 # variance of the model error to generate the catalog   \n",
    "            sigma2_obs = 1 # variance of the observation error to generate observations    \n",
    "        # run the data generation\n",
    "        catalog_bad, tej1, tej2 = AnDA_generate_data(GD)\n",
    "        # keep only a subset of variables\n",
    "        catalog_bad.analogs = catalog_bad.analogs[:,17:22]\n",
    "        catalog_bad.successors = catalog_bad.successors[:,17:22]\n",
    "        # parameters of the analog forecasting method\n",
    "        class AF:\n",
    "            k = 50 # number of analogs\n",
    "            neighborhood = global_analog_matrix\n",
    "            catalog = catalog_bad # catalog with analogs and successors\n",
    "            regression = 'local_linear' # chosen regression ('locally_constant', 'increment', 'local_linear')\n",
    "            sampling = 'gaussian' # chosen sampler ('gaussian', 'multinomial')\n",
    "        # parameters of the filtering method\n",
    "        class DA:\n",
    "            method = 'AnEnKF' # chosen method ('AnEnKF', 'AnEnKS', 'AnPF')\n",
    "            N = 100 # number of members (AnEnKF/AnEnKS) or particles (AnPF)\n",
    "            xb = xt.values[0,17:22]; B = 0.1*np.eye(n)\n",
    "            H = np.eye(n)\n",
    "            R = GD.sigma2_obs*np.eye(n)\n",
    "            @staticmethod\n",
    "            def m(x):\n",
    "                return AnDA_analog_forecasting(x,AF)\n",
    "        # run the analog data assimilation\n",
    "        x_hat_analog_bad = AnDA_data_assimilation(yo, DA)\n",
    "        # compute model evidence\n",
    "        ME_AnDA = zeros(K)\n",
    "        for k in range(K):\n",
    "            ME_AnDA[k] = model_evidence(x_hat_analog_good.loglik, x_hat_analog_bad.loglik, k, yo)\n",
    "        # stock results\n",
    "        tab_ME_AnDA[i_iter,i_F,:] = ME_AnDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model evidence as a function of evidence window\n",
    "for i_F in range(len(F_values)):\n",
    "    line2, = plot(yo.time[0:K], mean(tab_ME_AnDA[:,0,:], 0), 'g')\n",
    "    line3, = plot(yo.time[0:K], mean(tab_ME_AnDA[:,1,:], 0), 'b')\n",
    "    line4, = plot(yo.time[0:K], mean(tab_ME_AnDA[:,2,:], 0), 'r')\n",
    "    line5, = plot(yo.time[0:K], mean(tab_ME_AnDA[:,3,:], 0), 'm')\n",
    "    fill_between(yo.time[0:K], percentile(tab_ME_AnDA[:,0,:], 5, axis=0), percentile(tab_ME_AnDA[:,0,:], 95, axis=0),\n",
    "                 color='g', alpha=.1)\n",
    "    fill_between(yo.time[0:K], percentile(tab_ME_AnDA[:,1,:], 5, axis=0), percentile(tab_ME_AnDA[:,1,:], 95, axis=0),\n",
    "                 color='b', alpha=.1)\n",
    "    fill_between(yo.time[0:K], percentile(tab_ME_AnDA[:,2,:], 5, axis=0), percentile(tab_ME_AnDA[:,2,:], 95, axis=0),\n",
    "                 color='r', alpha=.1)\n",
    "    fill_between(yo.time[0:K], percentile(tab_ME_AnDA[:,3,:], 5, axis=0), percentile(tab_ME_AnDA[:,3,:], 95, axis=0),\n",
    "                 color='m', alpha=.1)\n",
    "                \n",
    "    xlim([yo.time[0],yo.time[K-1]])\n",
    "    ylim([-5,105])\n",
    "    legend([line2, line3, line4, line5], ['F=8 VS F=6', 'F=8 VS F=7', 'F=8 VS F=9', 'F=8 VS F=10'], prop={'size': 20}, loc=4)\n",
    "    xlabel('Evidence window (Lorenz-96 times)', size=20)\n",
    "    ylabel('Model evidence (%)', size=20)\n",
    "    title('AnDA with observations from F=8', size=20)\n",
    "    #savefig('/home/ptandeo/Dropbox/Documents/Figures/AnDA_model_evidence/model_evidence_F_6to10.png', bbox_inches='tight', dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
